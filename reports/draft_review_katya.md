Question:  What is your understanding of the experiment the team is replicating?  What question does it answer?  How clear is the team's explanation?

My understanding of the experiment is that they are comparing the probability distribution of different graphs with the degree based on how they sample the data (by node, by edge or by all friends). This comparison sheds insight about different types of graphs and how they are different. Furthermore, they look into different sampling methods and how it affects the probability distribution. They answered the question of how the differences in sampling methods might bias the results in different ways.

Might be helpful to include what the researchers learned from their experiment.

Methodology: Do you understand the methodology?  Does it make sense for the question?  Are there limitations you see that the team did not address?

The methodology used was sampling using three different ways (node,edges, all friends) and determining the probability distribution. There was also a comparison of several metrics, such as clustering coefficients and degeneracy on the random sample.

Results: Do you understand what the results are (not yet considering their interpretation)?  If they are presented graphically, are the visualizations effective?  Do all figures have labels on the axes and captions?

The results are very clear! There are titles/labels on each graphs and the colors are consistent. Maybe talk about cumulative probability distribution somewhere in the introduction?

Interpretation: Does the draft report interpret the results as an answer to the motivating question?  Does the argument hold water?

Since the question was looking at insights between sampling methods, the draft report does clearly answer the motivating question. However, it seems that they do not answer why the real world networks have coefficients very close to 0, so although the argument of how edge sampling might lead to bias samples makes sense, they are basing it on a sample that might not be correct.

Replication: Are the results in the report consistent with the results from the original paper?  If so, how did the

The results in the report are not consistent with the results from the original paper, and it is not very clear from their conclusion as to why.

Extension: Does the report explain an extension to the original experiment clearly?  Is it a sensible extension in the sense that it has the potential to answer an interesting question that the original experiment did not answer?

It does answer a question that the original paper did not answer because they examine the different biases that come from different sampling methods.

Progress: Is the team roughly where they should be at this point, with a replication that is substantially complete and an extension that is clearly defined and either complete or nearly so?

For sure!


Presentation: Is the report written in clear, concise, correct language?  Is it consistent with the audience and goals of the report?  Does it violate any of the recommendations in my style guide?

Overall the report is clear and concise, but there is some confusion about what you interpreted from the first experiment (before the exploration) and whether these were the same results as those discovered in the paper.

"selecting and edge" to "selecting an edge" (P2, L2)


Mechanics: Is the report in the right directory with the right file name?  Is it formatted professionally in Markdown?  Does it include a meaningful title and the full names of the authors?  Is the bibliography in an acceptable style?

heck yeah!
